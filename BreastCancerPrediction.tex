\documentclass{article}
\usepackage{blindtext}
\usepackage{url}
\usepackage{graphicx}

\title{Breast Cancer Prediction}
\author{Chiara Coscarelli\\[1ex]matr. 0512113869}

\begin{document}

\maketitle

\newpage
\tableofcontents
\newpage
\section{Introduzione}

Il cancro al seno (BC) è uno dei tumori più comuni tra le donne in tutto il mondo e, secondo le statistiche globali, rappresenta la maggior parte dei nuovi casi di cancro e dei decessi correlati al cancro, rendendolo un problema di salute pubblica significativo nella società odierna. La diagnosi precoce del BC può migliorare significativamente la prognosi e le possibilità di sopravvivenza, poiché può promuovere un trattamento clinico tempestivo per i pazienti. Una classificazione più accurata dei tumori benigni può evitare che i pazienti si sottopongano a trattamenti non necessari. Pertanto, la diagnosi corretta di BC e la classificazione dei pazienti in gruppi maligni o benigni è oggetto di molte ricerche.  <ADDlink al GitHub>


\subsection{Obiettivi}
Questo progetto di Fondamenti di Intelligenza Artificiale, il mio primo approccio in questo ambito, mira a osservare quali caratteristiche sono più utili nel predire il cancro maligno o benigno e a vedere le tendenze generali che potrebbero aiutarci nella selezione del modello. L’obiettivo è classificare se il cancro al seno è benigno o maligno. Ho scelto questa tematica perché relativamente semplice, e quindi in grado di farmi apprendere il più possibile le basi del Machine Learning.
Gli obiettivi principali includono:
\begin{itemize}
    \item L'analisi approfondita dei dati estrapolati da un dataset.
    \item L'identificazione di feature associate alle diagnosi.
    \item L'implementazione di un modello di apprendimento in grado di calcolare la probabilità che un tumore al seno sia benigno o maligno.
\end{itemize}

\subsection{Specifica PEAS}
\begin{itemize}
    \item Performance (misure di prestazione adottate per valutare l’operato di un agente), nel mio caso
    verranno valutate la precisione di classificazione e l’accuratezza.
    \item Environment (elementi che formano l’ambiente), nel mio caso è costituito dai dati clinici dei pazienti, inclusi parametri e misure relative al cancro al seno.
    \item Actuators (attuatori disponibili all’agente per intraprendere le azioni), nel mio caso sarà la capacità di predirre la presenza o assenza di cancro al seno.
    \item Sensors (sensori attraverso i quali l’agente riceve gli input percettivi), nel mio caso l’agente va ad acquisire dati clinici del paziente, tra cui risultati di esami, misure e caratteristiche correlate al cancro al seno.
\end{itemize}

\subsection{Caratteristiche dell'ambiente}
L'ambiente è:
DA FARE


\subsection{Analisi del problema}
La previsione del cancro al seno è un problema di apprendimento supervisionato, più in particolare di classificazione.Nelle successive sezioni vado a descrivere tutte le problematiche che ho affrontato.
Per quanto riguarda le tecnologie che ho utilizzato per lo sviluppo del progetto, abbiamo:
\begin{itemize}
    \item Python (in dettaglio le librerie per ML, come sickitLearn, Pandas, ecc.),
    \item JupyterNotebook all’interno dell’IDE PyCharm
    \item GitHub per il versionamento,
    \item Overleaf e Canva per documentazione e presentazione.
\end{itemize}

\newpage
\section{Data Understending}
Tale fase é composta da più punti:
\begin{itemize}
    \item Acquisizione dei dati
    \item Esplorazione dei dati
    \item Analisi della qualit`a dei dati
\end{itemize}

\subsection{Acquisizione dei dati}
L’acquisizione dei dati è il processo di raccolta, ed organizzazione dei dati necessari per andare a creare un modello di ML. Con gli obiettivi chiari e definiti, sono andato alla ricerca di un dataset fino a trovarne uno molto interessante su Kaggle.Il dataset preso in considerazione è presente al link: AGGIUNGI LINK


\subsection{Esplorazione dei dati}
Il dataset in esame contiene 569 righe e 32 colonne. ' Diagnosi ' è la colonna che useremo per predire, ovvero che dice se il cancro è M = maligno o B = benigno.  In questa fase vado ad analizzare, o meglio esplorare nel dettaglio i dati per comprenderli meglio.
Prima di tutto sono andata a fare una panoramica del dataset, andando a conteggiare quanti sample per ogni classe (B/M) fossero presenti.

\subsection{Analisi della qualità dei dati}
In questa fase vado ad analizzare i problemi di qualità dei dati rilevati durante la fase di esplorazione.
Possiamo  notare che la quantità di diagnosi B, è  maggiore rispetto alla quantità di diagnosi M. Difatti, andando ad approfondire, è risultata la presenza di:
\begin{itemize}
    \item 357 B (benigne)
    \item 212  M (maligne)
\end{itemize}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{image.png}
    \caption{percentuale di frequenza delle classi}
    \label{fig:enter-label}
\end{figure}
\newpage
Questo indica un forte sbilanciamento dei dati, ed è quindi un problema che dovrà essere risolto.
Altri problemi riscontrati:
\begin{itemize}
    \item una colonna del dataset totalmente nulla.
\end{itemize}
Questo problema sarà risolto nella sezione successiva, ovvero nella Data Preparation.

\newpage
\section{Data Preparation}
Tale fase mira a rendere i dati adatti per l’utilizzo nelle fasi successive del processo.
Questo processo include più punti:
\begin{itemize}
    \item data cleaning
    \item feature scaling
    \item feature selection
    \item data balancing
\end{itemize}
Quindi l’output di questa fase sarà un insieme di dati di input, che saranno utilizzati durante la
modellazione dell’algoritmo di ML.

\subsection{Data Cleaning}
In questa fase vanno corretti i problemi individuati in fase di Data understanding: nel mio caso la presenza di una colonna nulla; per poi passare alla trasformazione dei dati in modo da poter essere utilizzati da un algoritmo di apprendimento.
Quindi, innanzitutto, ho eliminato completamente la colonna dal dataset poichè era completamente vuota. Successivamente ho sostituito le stringhe ”B” e ”M” della colonna diagnosi rispettivamente con i valori 0 e 1, per garantire la compatibilità con gli algoritmi di classificazione binaria. Infine, ho controllato se fossero presenti valori nulli e valori duplicati.Nel mio caso non ce ne sono.

\subsection{Feature scaling}
In questa fase si vanno ad utilizzare delle tecniche per normalizzare o scalare i valori delle caratteristiche in modo da avere una scala uniforme. Questo serve per evitare che caratteristiche con scale molto diverse influenzino negativamente gli algoritmi di apprendimento. Questo può essere ottenuto normalizzando.Prima di scalare i dati però ho fatto lo split del Dataset, ovvero dividere l’insieme di partenza in due sottoinsiemi: uno perl’addestramento ed uno per il testing per prevenire problemi di data Leakage.
Infatti, se si esegue lo scaling prima di suddividere il dataset in set di addestramento e testing, potrebbe verificarsi un problema noto come "data leakage" (fuga di dati). Lo scaling basato sull'intero dataset potrebbe incorporare informazioni del set di testing nel set di addestramento, influenzando erroneamente le prestazioni del modello durante la fase di valutazione.

\subsection{Feature selection}
La feature selection `e il processo in cui si va a scegliere un sottoinsieme delle caratteristiche più
rilevanti dai dati originali per andare a ridurre la complessità del modello. Qui entra in gioco il
Feature Engineering ovvero il processo nel quale il progettista utilizza la propria conoscenza del
dominio per determinare le feature e dare piu o meno enfasi ad esse.
\newpage
Per calcolare la correlazione tra le variabili, possiamo usare un’ulteriore strumento: la heatmap,
una mappa che utilizza colori per visualizzare i valori dei coefficienti di correlazione tra le diverse
coppie di variabili nel dataset, consentendo di individuare facilmente relazioni tra di esse.
\begin{itemize}
    \item Le celle più scure o più chiare indicano correlazioni più forti o più deboli, rispettivamente.
    \item Le variabili sono fortemente correlate tra loro se hanno valori vicini a 1 o -1, mentre hanno una bassa correlazione se hanno valori vicini a 0.
\end{itemize}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{corr.png}
    \caption{matrice di correlazione}
    \label{fig:enter-label}
\end{figure}

Nel mio caso, dalla matrice di correlazione possiamo notare che ci sono alcune variabili altamente correlate, ovvero che contengono valori simili che possono portare problemi di multicollinearità nei modelli, quindi possiamo considerare di eliminarne una.Per scegliere quale tra queste eliminare sono andata a verificare come ciascuna delle variabili è correlata con la variabile dipendente, e ho deciso di mantenere la variabile maggiormente correlata alla variabile dipendete.In questo modo, si può portare il modello ad un miglioramento delle prestazioni.
Tra le variabili altamente correlate abbiamo:
\begin{itemize}
    \item  radius-mean, perimeter-mean e area-mean sono correlati tra loro e utilizziamo solo perimeter-mean.
    \item compactness-mean, concavity-mean and concave points-mean sono correlati tra loro e utilizziamo solo  concave points-mean
    \item radius-se, perimeter-se and area-se sono correlati tra loro e utilizziamo solo  perimeter-se
    \item radius-worst, perimeter-worst and area-worst sono correlati tra loro e utilizziamo solo  area-worst.
    \item Compactness-worst, concavity-worst and concave points-worst sono correlati tra loro e utilizziamo solo  concavity-worst
    \item Compactness-se, concavity-se and concave points-se sono correlati tra loro e utilizziamo solo  concavity-se.
    \item texture-mean, texture-worst  sono correlati tra loro e utilizziamo solo  texture-mean.
\end{itemize}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{corr2.png}
    \caption{Matrice di correlazione dopo aver eliminato le feature correlate}
    \label{fig:enter-label}
\end{figure}

\newpage
\subsection{Data Balancing}
Il Data Balancing si riferisce alle tecniche usate per convertire un dataset sbilanciato in un uno bilanciato.Avere un dataset sbilanciato può portare diversi problemi, tra questi previsioni sbilanciate e
innaccurate, nonchè problematiche di overfitting. Le tecniche applicabili sono due:
\begin{itemize}
    \item Undersampling
    \item Oversampling
\end{itemize}
Nel mio caso, il dataset è fortemente sbilanciato, con una presenza maggiore di istanze della classe Benigna. Quindi le possibilità sono due:
\begin{itemize}
    \item Eliminare istanze della classe benigna
    \item Aumentare le istanze della classe maligna
\end{itemize}
Tra le due, per evitare troppa duplicazione e quindi probabile overfitting, ho deciso di optare per la prima opzione, andando a considerare l’uso di Undersampling con RandomUnsersampler. Ho usato RandomUndersampling perché un dataset sbilanciato può portare a problemi di apprendimento, quindi il modello potrebbe avere difficoltà a identificare correttamente la classe minoritaria. Random Undersampling affronta questo problema riducendo casualmente il numero di campioni della classe maggioritaria, aiutando a bilanciare le proporzioni tra le classi.
